{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytorch.loss import CrossEntropyLoss\n",
    "from mytorch.optim import Adam\n",
    "from mytorch.dataloader import Dataloader\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from model import Model\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "epochs = []\n",
    "def plot(ax, epoch, train_loss, val_loss, train_accuracy, val_accuracy):\n",
    "    epochs.append(epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    ax[0].cla()\n",
    "    ax[0].plot(epochs, train_losses, label=\"train_loss\")\n",
    "    ax[0].plot(epochs, val_losses, label=\"val_loss\")\n",
    "    ax[1].cla()\n",
    "    ax[1].plot(epochs, train_accuracies, label=\"train_accuracy\")\n",
    "    ax[1].plot(epochs, val_accuracies, label=\"val_accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, img, target, transform=None):\n",
    "        self.img = img\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(images = img.astype(np.uint8))\n",
    "        img = (img-img.min())/img.max()\n",
    "        target = self.target[idx]\n",
    "        target = target*0.9+0.1/15.\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(data, target, length):\n",
    "    indices = list(range(len(data)))\n",
    "    random.shuffle(indices)\n",
    "    train_len = int(len(data)*length)\n",
    "    val_len = len(data)-train_len\n",
    "    train_data = [data[indices[i]] for i in range(train_len)]\n",
    "    train_target = [target[indices[i]] for i in range(train_len)]\n",
    "    val_data = [data[indices[i]] for i in range(train_len, train_len+val_len)]\n",
    "    val_target = [target[indices[i]] for i in range(train_len, train_len+val_len)]\n",
    "    return train_data, train_target, val_data, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target):\n",
    "    y = np.argmax(pred.a, axis=1)\n",
    "    t = np.argmax(target.a, axis=1)\n",
    "    count = np.where(y == t, 1, 0)\n",
    "    count = np.sum(count)\n",
    "    return count/len(pred.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 500\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "train_length = 0.8\n",
    "path = \"./weights/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "augseq = iaa.Sequential([\n",
    "    iaa.Crop(percent=(0, 0.03)),\n",
    "    iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.1))),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    iaa.Affine(\n",
    "    scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "    rotate=(-15, 15),\n",
    "    shear=(-3, 3)\n",
    "    ),\n",
    "    ], random_order=True\n",
    ")\n",
    "model = Model()\n",
    "celoss = CrossEntropyLoss()\n",
    "optim = Adam(model.get_params(), lr=lr)\n",
    "\n",
    "train_data = np.load(\"./1_data/train_data.npy\")\n",
    "train_label = np.load(\"./1_data/train_label.npy\")\n",
    "train_x, train_y, val_x, val_y = random_split(train_data, train_label, train_length)\n",
    "train_dataset = Dataset(train_x, train_y, augseq)\n",
    "val_dataset = Dataset(val_x, val_y)\n",
    "dataloader = Dataloader(train_dataset, batch_size, True)\n",
    "val_dataloader = Dataloader(val_dataset)\n",
    "size = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/500[========================================]loss: 1.8741401409222247 accuracy: 0.07750270270270276\n",
      "loss: 1.8407277319315072, val_loss: 1.8798197871550077, accuracy: 0.07749999989666667, val_accuracy: 0.08177083251562502\n",
      "1/500[========================================]loss: 1.7924514815729746 accuracy: 0.10458333333333333\n",
      "loss: 1.8211827504133995, val_loss: 1.8241792449608063, accuracy: 0.10458333319388889, val_accuracy: 0.11406249885937501\n",
      "2/500[----------------------------------------]loss: 1.8592406496377258 accuracy: 0.09375"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "for e in range(epoch):\n",
    "    progress = 0\n",
    "    model.train()\n",
    "    t_ac = 0\n",
    "    t_loss = 0\n",
    "    i = 0\n",
    "    for x, target in dataloader:\n",
    "        i += 1\n",
    "        progress += batch_size\n",
    "        optim.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = celoss(y, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        bar = int(progress/size*40)\n",
    "        t_ac += accuracy(y, target)\n",
    "        t_loss += float(loss.a)\n",
    "        if (model.conv1.weight.grad.max() < 1e-10):\n",
    "            print(\" !! conv1.weight.grad zero\")\n",
    "        print(\"\\r{}/{}[{}]loss: {} accuracy: {}\".format(e,epoch,\"=\"*bar+\"-\"*(40-bar),t_loss/i, t_ac/i), end=\"\")\n",
    "        del loss\n",
    "    t_ac /= i+1e-7\n",
    "    t_loss /= i+1e-7\n",
    "    v_ac = 0\n",
    "    v_loss = 0\n",
    "    i = 0\n",
    "    model.eval()\n",
    "    for val_x, val_y in val_dataloader:\n",
    "        i += 1\n",
    "        y = model(val_x)\n",
    "        v_ac += accuracy(y, val_y)\n",
    "        v_loss += float(celoss(y, val_y).a)\n",
    "    v_ac /= i+1e-7\n",
    "    v_loss /= i+1e-7\n",
    "    plot(ax, e, t_loss, v_loss, t_ac, v_ac)\n",
    "    print(f\"\\nloss: {t_loss}, val_loss: {v_loss}, accuracy: {t_ac}, val_accuracy: {v_ac}\")\n",
    "    if (e+1)%10 == 0:\n",
    "        with open(path+f\"{e}_weights{ac}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
