{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytorch.loss import CrossEntropyLoss\n",
    "from mytorch.optim import Adam\n",
    "from mytorch.dataloader import Dataloader\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from model import Model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, img, target, transform=None):\n",
    "        self.img = img\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(images = img.astype(np.uint8))\n",
    "        img = (img-img.min())/img.max()\n",
    "        target = self.target[idx]\n",
    "        target = target*0.9+0.1/15.\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(data, target, length):\n",
    "    indices = list(range(len(data)))\n",
    "    random.shuffle(indices)\n",
    "    train_len = int(len(data)*length)\n",
    "    val_len = len(data)-train_len\n",
    "    train_data = [data[indices[i]] for i in range(train_len)]\n",
    "    train_target = [target[indices[i]] for i in range(train_len)]\n",
    "    val_data = [data[indices[i]] for i in range(train_len, train_len+val_len)]\n",
    "    val_target = [target[indices[i]] for i in range(train_len, train_len+val_len)]\n",
    "    return train_data, train_target, val_data, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target):\n",
    "    y = np.argmax(pred.a, axis=1)\n",
    "    t = np.argmax(target.a, axis=1)\n",
    "    count = np.where(y == t, 1, 0)\n",
    "    count = np.sum(count)\n",
    "    return count/len(pred.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 500\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "train_length = 0.8\n",
    "path = \"./weights/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "augseq = iaa.Sequential([\n",
    "    iaa.Crop(percent=(0, 0.03)),\n",
    "    iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.1))),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    iaa.Affine(\n",
    "    scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "    rotate=(-15, 15),\n",
    "    shear=(-3, 3)\n",
    "    ),\n",
    "    ], random_order=True\n",
    ")\n",
    "model = Model()\n",
    "celoss = CrossEntropyLoss()\n",
    "optim = Adam(model.get_params(), lr=lr)\n",
    "\n",
    "train_data = np.load(\"./1_data/train_data.npy\")\n",
    "train_label = np.load(\"./1_data/train_label.npy\")\n",
    "train_x, train_y, val_x, val_y = random_split(train_data, train_label, train_length)\n",
    "train_dataset = Dataset(train_x, train_y, augseq)\n",
    "val_dataset = Dataset(val_x, val_y)\n",
    "dataloader = Dataloader(train_dataset, batch_size, True)\n",
    "val_dataloader = Dataloader(val_dataset)\n",
    "size = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/500[========================================]loss: 1.8747761344395568 accuracy: 0.070469798657718125\n",
      "loss: 1.8747761331897062, val_loss: 2.287323835784252, accuracy: 0.06999999995333334, val_accuracy: 0.07656249923437501\n",
      "1/500[========================================]loss: 1.8796298946257552 accuracy: 0.068759463087248366\n",
      "loss: 1.8796298933726687, val_loss: 2.1009516374397146, accuracy: 0.06874999995416667, val_accuracy: 0.10104166565625003\n",
      "2/500[========================================]loss: 1.8860330336205644 accuracy: 0.059583333333333335\n",
      "loss: 1.886033032363209, val_loss: 2.0582903852329166, accuracy: 0.05958333329361112, val_accuracy: 0.05468749945312501\n",
      "3/500[========================================]loss: 1.875787197147958 accuracy: 0.074166666666666677\n",
      "loss: 1.8757871958974335, val_loss: 2.070537303263586, accuracy: 0.07416666661722222, val_accuracy: 0.056770832765625015\n",
      "4/500[========================================]loss: 1.8742584285662045 accuracy: 0.06416666666666666\n",
      "loss: 1.8742584273166991, val_loss: 2.132000313879429, accuracy: 0.0641666666238889, val_accuracy: 0.06927083264062502\n",
      "5/500[========================================]loss: 1.8732351542384043 accuracy: 0.073333333333333335\n",
      "loss: 1.8732351529895808, val_loss: 2.169624441153559, accuracy: 0.07333333328444444, val_accuracy: 0.071354165953125\n",
      "6/500[========================================]loss: 1.8727064312028763 accuracy: 0.07083333333333333\n",
      "loss: 1.8727064299544054, val_loss: 2.301105433264386, accuracy: 0.07083333328611112, val_accuracy: 0.07395833259375001\n",
      "7/500[========================================]loss: 1.8676887387697316 accuracy: 0.072916666666666676\n",
      "loss: 1.8676887375246058, val_loss: 2.37842648777957, accuracy: 0.07291666661805556, val_accuracy: 0.06406249935937501\n",
      "8/500[========================================]loss: 1.8673895674693415 accuracy: 0.06583333333333333\n",
      "loss: 1.867389566224415, val_loss: 2.1050616903994395, accuracy: 0.06583333328944445, val_accuracy: 0.068229165984375\n",
      "9/500[========================================]loss: 1.866435950249925 accuracy: 0.0637558389261744974\n",
      "loss: 1.8664359490056344, val_loss: 1.9849808478793416, accuracy: 0.0637499999575, val_accuracy: 0.0687499993125\n",
      "10/500[========================================]loss: 1.8538320257576653 accuracy: 0.062916666666666664\n",
      "loss: 1.8538320245217772, val_loss: 2.1485068868168793, accuracy: 0.06291666662472223, val_accuracy: 0.05781249942187501\n",
      "11/500[========================================]loss: 1.8603062454945898 accuracy: 0.064166666666666664\n",
      "loss: 1.8603062442543856, val_loss: 1.9176833411900103, accuracy: 0.0641666666238889, val_accuracy: 0.052604166140625006\n",
      "12/500[========================================]loss: 1.8577309328541947 accuracy: 0.062580536912751685\n",
      "loss: 1.8577309316157073, val_loss: 1.8866494111949799, accuracy: 0.06249999995833334, val_accuracy: 0.055729166109375006\n",
      "13/500[========================================]loss: 1.8526732040711602 accuracy: 0.063333333333333346\n",
      "loss: 1.8526732028360449, val_loss: 1.9067613779962234, accuracy: 0.06333333329111111, val_accuracy: 0.07552083257812502\n",
      "14/500[========================================]loss: 1.8464705007748379 accuracy: 0.070833333333333335\n",
      "loss: 1.8464704995438577, val_loss: 1.9215066237465617, accuracy: 0.07083333328611112, val_accuracy: 0.06718749932812501\n",
      "15/500[========================================]loss: 1.8422438708104494 accuracy: 0.07208333333333333\n",
      "loss: 1.842243869582287, val_loss: 2.024106063237567, accuracy: 0.07208333328527779, val_accuracy: 0.07083333262500001\n",
      "16/500[========================================]loss: 1.8461807795702407 accuracy: 0.057566442953020135\n",
      "loss: 1.8461807783394535, val_loss: 2.0356924371393212, accuracy: 0.057499999961666666, val_accuracy: 0.07083333262500001\n",
      "17/500[========================================]loss: 1.843807008816332 accuracy: 0.0666666666666666744\n",
      "loss: 1.8438070075871276, val_loss: 1.867097458630957, accuracy: 0.06666666662222223, val_accuracy: 0.06718749932812501\n",
      "18/500[========================================]loss: 1.8404299847568173 accuracy: 0.070050335570469844\n",
      "loss: 1.840429983529864, val_loss: 2.1318470994676706, accuracy: 0.06999999995333334, val_accuracy: 0.07031249929687501\n",
      "19/500[========================================]loss: 1.8413563195375828 accuracy: 0.064166666666666666\n",
      "loss: 1.8413563183100121, val_loss: 1.8791948049655562, accuracy: 0.0641666666238889, val_accuracy: 0.06666666600000001\n",
      "20/500[========================================]loss: 1.8404205079031244 accuracy: 0.069166666666666674\n",
      "loss: 1.8404205066761776, val_loss: 1.967491958757139, accuracy: 0.06916666662055555, val_accuracy: 0.061458332718750015\n",
      "21/500[========================================]loss: 1.8387724082925123 accuracy: 0.070416666666666675\n",
      "loss: 1.838772407066664, val_loss: 1.9702785265684544, accuracy: 0.07041666661972222, val_accuracy: 0.055729166109375006\n",
      "22/500[========================================]loss: 1.8382830294464305 accuracy: 0.065833333333333335\n",
      "loss: 1.8382830282209084, val_loss: 1.9201521011153255, accuracy: 0.06583333328944445, val_accuracy: 0.06354166603125001\n",
      "23/500[========================================]loss: 1.8363817858813176 accuracy: 0.064583333333333346\n",
      "loss: 1.8363817846570631, val_loss: 1.849527700926191, accuracy: 0.06458333329027778, val_accuracy: 0.07083333262500001\n",
      "24/500[========================================]loss: 1.8364028274693867 accuracy: 0.070469798657718126\n",
      "loss: 1.8364028262451182, val_loss: 1.858257977924751, accuracy: 0.06999999995333334, val_accuracy: 0.09322916573437501\n",
      "25/500[========================================]loss: 1.8325005640456988 accuracy: 0.08083333333333333\n",
      "loss: 1.832500562824032, val_loss: 2.0135987547794647, accuracy: 0.08083333327944445, val_accuracy: 0.07187499928125002\n",
      "26/500[========================================]loss: 1.8221150909304655 accuracy: 0.10666666666666667\n",
      "loss: 1.8221150897157221, val_loss: 2.4141612189005355, accuracy: 0.10666666659555556, val_accuracy: 0.10156249898437501\n",
      "27/500[========================================]loss: 1.804007546390801 accuracy: 0.129583333333333333\n",
      "loss: 1.8040075451881294, val_loss: 1.9470276313893247, accuracy: 0.12958333324694446, val_accuracy: 0.09895833234375002\n",
      "28/500[===================---------------------]loss: 1.7889553730459988 accuracy: 0.12239583333333333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e0e302079c62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mceloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\myarray\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0midentity_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\myarray\\mytorch\\layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0minput_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim2col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0minput_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0minput_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\myarray\\mytorch\\tensor.py\u001b[0m in \u001b[0;36mmax\u001b[1;34m(input, axis)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                 \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for e in range(epoch):\n",
    "    progress = 0\n",
    "    model.train()\n",
    "    t_ac = 0\n",
    "    t_loss = 0\n",
    "    i = 0\n",
    "    for x, target in dataloader:\n",
    "        i += 1\n",
    "        progress += batch_size\n",
    "        optim.zero_grad()\n",
    "        for k in range(3):\n",
    "            y = model(x)\n",
    "            loss = celoss(y, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        bar = int(progress/size*40)\n",
    "        t_ac += accuracy(y, target)\n",
    "        t_loss += float(loss.a)\n",
    "        print(\"\\r{}/{}[{}]loss: {} accuracy: {}\".format(e,epoch,\"=\"*bar+\"-\"*(40-bar),t_loss/i, t_ac/i), end=\"\")\n",
    "        del loss\n",
    "    t_ac /= i+1e-7\n",
    "    t_loss /= i+1e-7\n",
    "    v_ac = 0\n",
    "    v_loss = 0\n",
    "    i = 0\n",
    "    model.eval()\n",
    "    for val_x, val_y in val_dataloader:\n",
    "        i += 1\n",
    "        y = model(val_x)\n",
    "        v_ac += accuracy(y, val_y)\n",
    "        v_loss += float(celoss(y, val_y).a)\n",
    "    v_ac /= i+1e-7\n",
    "    v_loss /= i+1e-7\n",
    "    train_losses.append(t_loss)\n",
    "    val_losses.append(v_loss)\n",
    "    train_accuracies.append(t_ac)\n",
    "    val_accuracies.append(v_ac)\n",
    "    print(f\"\\nloss: {t_loss}, val_loss: {v_loss}, accuracy: {t_ac}, val_accuracy: {v_ac}\")\n",
    "    if (e+1)%10 == 0:\n",
    "        with open(path+f\"{e}_weights{v_ac}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(len(train_losses))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[0].set_xlabel(\"epochs\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].plot(epochs, train_losses, label=\"train_loss\")\n",
    "ax[0].plot(epochs, val_losses, label=\"val_loss\")\n",
    "ax[0].legend()\n",
    "ax[1].set_title(\"accuracy\")\n",
    "ax[1].set_xlabel(\"epochs\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].plot(epochs, train_accuracies, label=\"train_accuracies\")\n",
    "ax[1].plot(epochs, val_accuracies, label=\"val_accuracies\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(train_data, train_label, augseq)\n",
    "dataloader = Dataloader(train_dataset, batch_size, True)\n",
    "size = len(train_dataset)\n",
    "epoch = 100\n",
    "\n",
    "for e in range(epoch):\n",
    "    progress = 0\n",
    "    model.train()\n",
    "    t_ac = 0\n",
    "    t_loss = 0\n",
    "    i = 0\n",
    "    for x, target in dataloader:\n",
    "        i += 1\n",
    "        progress += batch_size\n",
    "        optim.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = celoss(y, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        bar = int(progress/size*40)\n",
    "        t_ac += accuracy(y, target)\n",
    "        t_loss += float(loss.a)\n",
    "        if (model.conv1.weight.grad.max() < 1e-10):\n",
    "            print(\" !! conv1.weight.grad zero\")\n",
    "        print(\"\\r{}/{}[{}]loss: {} accuracy: {}\".format(e,epoch,\"=\"*bar+\"-\"*(40-bar),t_loss/i, t_ac/i), end=\"\")\n",
    "        del loss\n",
    "    if (e+1)%10 == 0:\n",
    "        with open(path+f\"epoch{e}_weights{t_ac}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
